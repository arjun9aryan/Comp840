{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A \"Hello World\" Example of Machine Learning - Revisit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Iris dataset from scikit-learn. \n",
    "\n",
    "The first column represents Sepal length, the second column represents Sepal width,  the third column represents the petal length, and the fourth column the petal width of the flower samples. The classes (type of species) are already converted to integer labels where 0=Iris-Setosa, 1=Iris-Versicolor, 2=Iris-Virginica.\n",
    "\n",
    "Here, we are using only two features: the third and fourth columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:,[2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class labels: [0 1 2]\n"
    }
   ],
   "source": [
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn algorithms support multi-class classification via the One-Versus-Rest(OvR) method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into 70% training and 30% test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Labels counts in y: [50 50 50]\nLabels counts in y_train: [35 35 35]\nLabels counts in y_test: [15 15 15]\n"
    }
   ],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=0.1,\n      fit_intercept=True, max_iter=100, n_iter=None, n_iter_no_change=5,\n      n_jobs=None, penalty=None, random_state=42, shuffle=True, tol=None,\n      validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(max_iter=100, eta0=0.1, random_state=42)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model with the hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 2\n"
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.9555555555555556\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 2, 2])"
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "X_new = [[1.1, 0.2],[0.4, 1.9], [1.4, 0.2]]\n",
    "y_new = ppn.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.81481481, 0.81481481, 0.81481481, 0.875     ])"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ppn, X_train_std, y_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "source": [
    "2-features: sccuracy score: array([0.88888889, 0.48148148, 0.7037037 , 0.95833333])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Use all four features to train the model and use cross validaton to check if the results better? Briefly explain why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:]\n",
    "#selecting 0 to 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "class labels: [0 1 2]\n"
    }
   ],
   "source": [
    "print('class labels:',np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Labels counts in y: [50 50 50]\nLabels counts in y_train: [35 35 35]\nLabels counts in y_test: [15 15 15]\n"
    }
   ],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=0.1,\n      fit_intercept=True, max_iter=100, n_iter=None, n_iter_no_change=5,\n      n_jobs=None, penalty=None, random_state=42, shuffle=True, tol=None,\n      validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(max_iter=100, eta0=0.1, random_state=42)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 1\n"
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.9777777777777777\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 2, 2])"
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "X_new = [[4.4,3.2,1.3,0.2],[6.5,2.8,4.6,1.5], [6.3,2.8,5.1,1.5]]\n",
    "y_new = ppn.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.92592593, 0.88888889, 0.81481481, 0.91666667])"
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ppn, X_train_std, y_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "source": [
    "### The four feature has better values in both the missclassified samples and the accuracy."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Try with the scikit-learn stochastic gradient descent model instead of perceptron. Use all four features. Evaluate with cross-validation how does the model perform in terms of accuracy using both two features and four features. "
   ]
  },
  {
   "source": [
    "# Using 4 feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:]\n",
    "#selecting 0 to 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "class labels: [0 1 2]\n"
    }
   ],
   "source": [
    "y=iris.target\n",
    "print('class labels:',np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n       early_stopping=False, epsilon=0.1, eta0=0.1, fit_intercept=True,\n       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n       power_t=0.5, random_state=42, shuffle=True, tol=None,\n       validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(max_iter=100, eta0=0.1, random_state=42)\n",
    "sgd.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 1\n"
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=sgd.predict(X_test_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy:0.9777777777777777\n"
    }
   ],
   "source": [
    "print('Accuracy:' + str(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 2, 2])"
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "X_new = [[4.4,3.2,1.3,0.2],[6.5,2.8,4.6,1.5], [6.3,2.8,5.1,1.5]]\n",
    "y_new = sgd.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.92592593, 0.88888889, 0.92592593, 0.875     ])"
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd, X_train_std, y_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "source": [
    "# Using 2 feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class labels: [0 1 2]\nLabels counts in y: [50 50 50]\nLabels counts in y_train: [35 35 35]\nLabels counts in y_test: [15 15 15]\nMisclassified samples: 2\nAccuracy: 0.9555555555555556\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.85185185, 0.96296296, 0.81481481, 0.95833333])"
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,[2,3]]\n",
    "y = iris.target\n",
    "print('Class labels:', np.unique(y))\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd.fit(X_train_std, y_train)\n",
    "y_pred = sgd.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))\n",
    "print('Accuracy: ' + str(accuracy_score(y_test,y_pred)))\n",
    "X_new = [[5.4,0.4],[5.6, 3.0], [7.7, 2.8]]\n",
    "y_new = sgd.predict(X_new)\n",
    "y_new\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd, X_train_std, y_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "source": [
    "### Using the SGDclassifier also, the four feature has the better accuracy rate. but, the cross validate values of 2-feature look better than four feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.3 64-bit",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}